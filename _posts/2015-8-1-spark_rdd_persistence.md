---
layout: post
category: Spark
title: Spark RDD持久化分析
tagline: by Weber
tags: [Spark RDD]
---
Spark存储管理模块主要做两件事情，一是RDD的缓存，二是Shuffle数据的持久化。

<!--more-->

#RDD分区和数据块的关系#

当持久化一个RDD的时候，每个节点都将参与计算的所有分区数据持久化到内存中，并且可以被该RDD后续的action所使用。对于一个RDD的操作，将施行与该RDD的所有分区之上，那么分区和数据块有什么关系呢？分区是逻辑上的概念，数据块为其对应的实际的数据，且分区与数据块一一对应。
对于分区与数据块之间的映射是通过名字进行对应的。在Spark内部为每一个RDD赋予一个独立的ID，对每个RDD的分区也有一个独立的索引号，那么，通过*ID+索引*来唯一确定一个数据块，当我们读取缓存中的RDD时，根据上述索引来从存储管理模块中取得对应的数据块。

#内存缓存#

Spark默认是基于内存的持久化方式缓存RDD，RDD中的所有分区对应的数据块都会被内存管理模块的内存缓存所管理，内存缓存在内部维护了一个以数据块名称为键，块内容为值得哈希表。
那么如果Spark的内存缓存达到了所设置的阈值时该如何处理呢？在Spark中有这样一个配置：

	spark.storage.memeoryFraction 默认为0.6
	
默认的0.6表示JVM的60%的内存可以被内存缓存用来存储块内容，当大于60%时会触发Spark释放内存缓存空间：丢弃一些数据块或者是持久化到硬盘上。具体到操作方式依赖于RDD的持久化选项。
直接删除的话可能会对Spark错误恢复有所影响，如果删除后其祖先RDD可以被回溯调用，那么可以通过计算重新生成该RDD，则不会对错误恢复机制有所影响，反之程序会报错。

#磁盘缓存#

除了可将数据缓存在内存之外，还可以间数据缓存于磁盘。通过配置：

	spark.local.dir
	
选项来配置磁盘缓存数据的存放目录，磁盘缓存初始化时会在该目录下创建磁盘缓存文件夹，用以存放对应的缓存文件。

在磁盘缓存中，一个数据块对应一个磁盘文件系统中的一个文件。

#持久化选项#

当我们将一个RDD持久化时，可以通过RDD的persist()和cache()操作来进行操作，当我们首次执行action操作时会把该RDD对应的数据实体化并存储到内存或者硬盘中，再次使用该RDD时可直接通过缓存来获得数据，无须再次计算。缓存的数据块是同错恢复的，若RDD数据块丢失，可通过继承关系自动重算来获得。

Spark的持久化选项为：

| Options   |      Dscription      |  
|----------|:-------------|
| MEMORY_ONLY|  默认的持久化选项,以非序列化的方式存储到JVM内存堆之中，如果内存缓存无法容纳该RDD，则一部分分区将不会被缓存到内存中。 |
| MEMORY_AND_DISK |    同上，区别在于内存缓存无法容纳的话会将其存储于磁盘上   |
| MEMORY_ONLY_SER | 同1，但是是以序列化的方式存储，其占用空间更小，但是读取的时候需要耗费更多的CPU资源来进行反序列化 |
| MEMORY_AND_DISK_SER | 同上，区别在于内存缓存不下后会被存储于磁盘上 |
| DISK_ONLY | 缓存与磁盘之上 |
| MEMORY\_ONLY\_2 <br> MEMORY_AND_DISK_2| 和1、2相似，增加缓存份数至其他节点之上 |

用户可以根据程序的情况和机器的配置合理选择持久化的范式，以合理利用机器资源。